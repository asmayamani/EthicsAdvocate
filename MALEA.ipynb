{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Fxj-cKoKabe"
      },
      "outputs": [],
      "source": [
        "!pip install autogen-agentchat~=0.2\n",
        "!pip install numpy==1.26.4 flaml==2.1.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "from typing import Annotated\n"
      ],
      "metadata": {
        "id": "CUl_ZC16KnR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.environ.get(\"API_KEY\")\n"
      ],
      "metadata": {
        "id": "WKuH0Qi_KppX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen\n",
        "import autogen"
      ],
      "metadata": {
        "id": "Ipky3zK_KuiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_summery = \"\"\"INPUT YOUR SYSTEM SUMMERY HERE\"\"\""
      ],
      "metadata": {
        "id": "5xVIQbkOKzTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"\"\"Generate five or more ethics requirements, focusing on Transparency, Fairness, and Data, in the form of user stories with acceptance criteria, for building a system with the following summary.: \"\"\" + system_summery\n",
        "config_list = {\n",
        "        \"cache_seed\": None,\n",
        "        \"model\": 'gemini-2.0-flash',\n",
        "        \"base_url\": \"https://generativelanguage.googleapis.com/v1beta\",\n",
        "        \"temperature\": 1,\n",
        "    }\n",
        "advocate = autogen.AssistantAgent(\n",
        "    name=\"Advocate\",\n",
        "    llm_config=config_list,\n",
        "    max_consecutive_auto_reply=4,\n",
        "    system_message=\"\"\"\n",
        "      You are an ethics advocate, known for your commitment to spotting ethical issues related to each stakeholder involved. Values you focus on are:\n",
        "      (1) Transparency, including: Internal and External Transparency, Explainability, Communication, Documentation, Traceability, System reliability\n",
        "      (2) Fairness, including: Accessibility, Inclusion,\n",
        "      (3) Data, including: Privacy, Data quality, Access to data\n",
        "      Your task is to scrutinize the existing requirements for any potential violation of these values or suggest new ethics-related requirements.\n",
        "      Think about each of the ethical challenges and its subpoints carefully and solve them one step at a time.\n",
        "      Acceptance criteria must be specific regarding ethical issues. No use of general words like (all ages, all skin tones, all genders) is allowed. Enumerations of such categories are required.\n",
        "      Do not introduce frameworks; just a requirements draft. If you don't have any additional suggestions or comments, state that: \"The requirements are approved from an ethics point of view\".\n",
        "    \"\"\",\n",
        ")\n",
        "qualityA = autogen.AssistantAgent(\n",
        "    name=\"Quality_Assurance\",\n",
        "    llm_config=config_list,\n",
        "    system_message=\"\"\"\n",
        "    You are a quality assurance professional, known for your commitment to spotting quality issues.\n",
        "    Quality traits that we want are for the requirement to be atomic, minimal, estimatable, Problem-oriented, and Unambiguous.\n",
        "    Your task is to scrutinize requirements for any potential violation of these quality issues.\n",
        "    Think about each of the quality criteria carefully and report violations one point at a time, if present.\n",
        "    If you don't have any major issues or comments state that: \"The requirements are approved from a quality point of view,\" then repeat the requirements and state they need ethical review.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "engineer = autogen.AssistantAgent(\n",
        "    name=\"engineer\",\n",
        "    llm_config=config_list,\n",
        "    system_message=\"\"\"\n",
        "    You are a requirements engineer, known for your precision and thoughtfulness.\n",
        "    You should improve the quality of the content based on the feedback you get from critics and ethics advocates. Always carry on with the latest set of agreed requirements.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "document = autogen.AssistantAgent(\n",
        "    name=\"documenter\",\n",
        "    llm_config=config_list,\n",
        "    system_message=\"\"\"\n",
        "    You are an assistant responsible for printing out or listing the last version of the agreed-upon requirement.\n",
        "    Do not just comment on them. List the final requirements as a bulleted list, along with their acceptance criteria.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "def custom_speaker_selection_func(last_speaker: autogen.Agent, groupchat: autogen.GroupChat):\n",
        "    \"\"\"Define a customized speaker selection function.\n",
        "    A recommended way is to define a transition for each speaker in the groupchat.\n",
        "\n",
        "    Returns:\n",
        "        Return an `Agent` class or a string from ['auto', 'manual', 'random', 'round_robin'] to select a default method to use.\n",
        "    \"\"\"\n",
        "    messages = groupchat.messages\n",
        "    print(\"Messages: \", messages[-1])\n",
        "    if last_speaker is qualityA:\n",
        "        if \"The requirements are approved from a quality point of view\" in messages[-1][\"content\"]:\n",
        "            return advocate\n",
        "        else:\n",
        "            return engineer\n",
        "    elif last_speaker is engineer:\n",
        "      if len(messages) < 2 or messages[-2][\"name\"] == qualityA.name:\n",
        "         if \"The requirements are approved from a quality point of view\" in messages[-1][\"content\"]:\n",
        "            return advocate\n",
        "         return qualityA\n",
        "      elif \"The requirements are approved from an ethics point of view\" in messages[-2][\"content\"]:\n",
        "          return document\n",
        "      elif count_name_occurrences(messages,advocate.name) == 2:\n",
        "          return document\n",
        "      else:\n",
        "          return advocate\n",
        "\n",
        "    elif last_speaker is advocate:\n",
        "      if \"The requirements are approved from an ethics point of view\" in messages[-1][\"content\"]:\n",
        "          # If the last message is approved, let the engineer to speak\n",
        "          return document\n",
        "      else:\n",
        "          return engineer\n",
        "    elif last_speaker is document:\n",
        "      return user_proxy\n",
        "    return document\n",
        "\n",
        "def count_name_occurrences(messages, target_name):\n",
        "    count = sum(1 for msg in messages if msg.get(\"name\") == target_name)\n",
        "    print(f\"Occurrences of '{target_name}': {count}\")\n",
        "    return count\n",
        "\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User\",\n",
        "    human_input_mode=\"ALWAYS\",\n",
        "    llm_config=config_list,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
        "    code_execution_config={\n",
        "        \"last_n_messages\": 1,\n",
        "        \"work_dir\": \"my_code\",\n",
        "        \"use_docker\": False,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "groupchat = autogen.GroupChat( agents=[user_proxy, engineer, advocate, qualityA,document],\n",
        "    messages=[],\n",
        "    max_round=20,\n",
        "    speaker_selection_method=custom_speaker_selection_func,\n",
        "\n",
        ")\n",
        "\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=config_list)\n",
        "\n",
        "results = manager.initiate_chat(\n",
        "    engineer,\n",
        "    message=task,\n",
        "    summary_method=\"last_msg\",\n",
        "    max_turns=20,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "-kJBw4ocK53Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}